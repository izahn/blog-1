<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>A Hugo website</title>
    <link>/</link>
    <description>Recent content on A Hugo website</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 07 Dec 2017 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Marginal effects in models with fixed effects</title>
      <link>/2017/12/07/marginal-effects-in-models-with-fixed-effects/</link>
      <pubDate>Thu, 07 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/12/07/marginal-effects-in-models-with-fixed-effects/</guid>
      <description>Marginal effects in a linear model Stata’s margins command has been a powerful tool for many economists. It can calculate predicted means as well as predicted marginal effects. However, we do need to be careful when we use it when fixed effects are included. In a linear model, everything works out fine. However, in a non-linear model, you may not want to use margins, since it’s not calculating what you have in mind.</description>
    </item>
    
    <item>
      <title>What model to use for rare events</title>
      <link>/2017/10/26/rare-event/</link>
      <pubDate>Thu, 26 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/10/26/rare-event/</guid>
      <description>Introducation In empirical studies, people are worried about rare event situation. That is, when you have, for example, lots of 0’s and only a few 1’s, or vice versa. Do you run a logit model, or do you use a “rare event logit”? When should you use either approach? Or there is a third approach?
Paul Allison said in his blog (https://statisticalhorizons.com/logistic-regression-for-rare-events):
“Prompted by a 2001 article by King and Zeng, many researchers worry about whether they can legitimately use conventional logistic regression for data in which events are rare.</description>
    </item>
    
    <item>
      <title>Causal Forest in panel data </title>
      <link>/2017/10/23/causal-forest-in-panel-data/</link>
      <pubDate>Mon, 23 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/10/23/causal-forest-in-panel-data/</guid>
      <description>Introduction In this simulation exercise, we use Causal Forest (Now is implemented in Generalized Random Forest) (https://github.com/swager/grf) to calculated conditional average treatment effect (or heterogenous treatment effect). We assume three different data generating processes. The first one is a linear interaction between a variable of interest and the treatment dummy. The second one assumes a nonlinear function (a step function) of a variable of interest, say \(X\), and the treatment dummy \(W\).</description>
    </item>
    
    <item>
      <title>Which count data model to use</title>
      <link>/2017/10/10/poisson/</link>
      <pubDate>Tue, 10 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/10/10/poisson/</guid>
      <description>A comparison of various count data models with extra zeros In empirical studies, data sets with a lot of zeros are often hard to model. There are various models to deal with it: zero-inflated Poisson model, Negative Binomial (NB)model, hurdle model, etc.
Here we are following a zero-inflated model’s thinking: model the data with two processes. One is a Bernoulli process, the other one is a count data process (Poisson or NB).</description>
    </item>
    
    <item>
      <title>Using machine learning for causal effect in observational study</title>
      <link>/2017/09/21/tmle/</link>
      <pubDate>Thu, 21 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/09/21/tmle/</guid>
      <description>A simulation for an OLS model In an observational study, we need to assume we have the functional form to get causal effect estimated correctly, in addtion to the assumption of treatment being exogenous.
library(MASS) library(ggplot2) library(dplyr) ## ## Attaching package: &amp;#39;dplyr&amp;#39; ## The following object is masked from &amp;#39;package:MASS&amp;#39;: ## ## select ## The following objects are masked from &amp;#39;package:stats&amp;#39;: ## ## filter, lag ## The following objects are masked from &amp;#39;package:base&amp;#39;: ## ## intersect, setdiff, setequal, union library(tmle) ## Loading required package: SuperLearner ## Loading required package: nnls ## Super Learner ## Version: 2.</description>
    </item>
    
    <item>
      <title>红楼梦 作者分析</title>
      <link>/2017/09/19/red-chamber/</link>
      <pubDate>Tue, 19 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/09/19/red-chamber/</guid>
      <description>简介 在本文中我们用机器学习和统计的方法来分析红楼梦的作者。红楼梦是中国最著名的小说之一(https://en.wikipedia.org/wiki/Dream_of_the_Red_Chamber)。 大多数人认为前八十回为曹雪芹所作， 后四十回为后人续作。 除非我们从考古中发现证据，唯一能告诉我们的便是小说本身。我们可以从文章的用词风格来判断作者。 即使续作者尽量模仿原作者的风格，也很难不在字里行间露出自己固有的风格。（我们也许可以用同样的方法来鉴定真画和假画，但是需要有原作者的大量画作）。
我是从这里下载的红楼梦原著120回版（具体哪个版本我也没仔细研究）: http://www.shuyaya.cc/book/2034/#download
我用了R中的 “Rwordseg” 来做中文分词。 就是把一句话分成词和词组。 然后用了 “cleanNLP” 得到分词频率矩阵 （“term frenquency matrix”）。 然后在最后一个模型用到 “topicmodels”。
 读入文本进行分词 这一部分就是读入文本， 把它分为120回，每一回作为一个文本， 然后分词。
# analysis starts here library(rticles) library(cleanNLP) library(readr) library(stringi) library(ggplot2) library(glmnet) library(ggrepel) library(viridis) library(magrittr) library(topicmodels) library(tidyverse) library(rJava) library(Rwordseg) library(RColorBrewer) library(tm) require(readtext) honglou1 &amp;lt;- readtext(&amp;quot;~/projects/honglongmeng/honglou1.txt&amp;quot;, text_field = &amp;quot;texts&amp;quot;) # here is to split into chapters using stringr&amp;#39;s splitting functions my_split &amp;lt;- function(text) { pattern &amp;lt;- &amp;#39;第.{1,3}回 &amp;#39; x &amp;lt;- str_split(text, pattern)[[1]] y &amp;lt;- str_extract_all(text, pattern)[[1]] data.</description>
    </item>
    
    <item>
      <title>Dream of the Red Chamber</title>
      <link>/2017/09/15/hong-lou-author-detection/</link>
      <pubDate>Fri, 15 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/09/15/hong-lou-author-detection/</guid>
      <description>Introduction In this post, I am trying to study the authorship of Dream of the Red Chamber (https://en.wikipedia.org/wiki/Dream_of_the_Red_Chamber). It has been controvertial who the author of the last 40 chapters of this most-well-known book in China. Many people believed that the first 80 chapters were written by Cao Xueqin, but the last 40 were additions by someone else.
The original text was downloaded here: http://www.shuyaya.cc/book/2034/#download
I used R’s packages “Rwordseg” to get tokens from the original text.</description>
    </item>
    
    <item>
      <title>About me</title>
      <link>/about/</link>
      <pubDate>Thu, 05 May 2016 21:48:51 -0700</pubDate>
      
      <guid>/about/</guid>
      <description>This is a blog site for mostly statistical blogs. I am a statistician at HBS My linkedin page.</description>
    </item>
    
  </channel>
</rss>